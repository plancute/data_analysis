{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14_1_베스트_모델_만들기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1sk_4O-MoYg_xxfFi9pUVBccuit8HiHza",
      "authorship_tag": "ABX9TyN1xxLogSyFqBEyfAWC7t2Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plancute/python/blob/master/deeplearning/code/14_1_%EB%B2%A0%EC%8A%A4%ED%8A%B8_%EB%AA%A8%EB%8D%B8_%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT5tDd0bkP-U",
        "colab_type": "text"
      },
      "source": [
        "## 14장 베스트 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xSVSVVOmyi-",
        "colab_type": "text"
      },
      "source": [
        "- 학습한 code <br>\n",
        "  deep_code/08_Wine.py <br>\n",
        "  deep_code/09_Wine_Checkpoint.py <br>\n",
        "  deep_code/10_Wine_Overfit_Graph.py <br>\n",
        "  deep_code/11_Wine_Early_Stop.py <br>\n",
        "  deep_code/12_Wine_Check_and_Stop.py <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3MRBpfymwg3",
        "colab_type": "text"
      },
      "source": [
        "<< deep_code/08_Wine.py >>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjhfAlj9msqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "ad7c36d4-cce5-473f-ffda-5edde816e1ba"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm18SA09hI-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seed 값 설정\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqoC2O4xnGGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 불러오기 (전체 6497개 -> 15% 975개)\n",
        "df_pre = pd.read_csv('/content/drive/My Drive/data/wine.csv', header=None)\n",
        "df = df_pre.sample(frac=0.15)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STt9q2klnN7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "48ac2cfd-6c1e-46db-a7ba-f809ae23f394"
      },
      "source": [
        "# 데이터 확인 (975 X 13)\n",
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 975 entries, 5316 to 413\n",
            "Data columns (total 13 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       975 non-null    float64\n",
            " 1   1       975 non-null    float64\n",
            " 2   2       975 non-null    float64\n",
            " 3   3       975 non-null    float64\n",
            " 4   4       975 non-null    float64\n",
            " 5   5       975 non-null    float64\n",
            " 6   6       975 non-null    float64\n",
            " 7   7       975 non-null    float64\n",
            " 8   8       975 non-null    float64\n",
            " 9   9       975 non-null    float64\n",
            " 10  10      975 non-null    float64\n",
            " 11  11      975 non-null    int64  \n",
            " 12  12      975 non-null    int64  \n",
            "dtypes: float64(11), int64(2)\n",
            "memory usage: 106.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl7BnKeJ4lxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_info = pd.DataFrame([\"주석산 농도\",\"아세트산 농도\",\"구연산 농도\",\"잔류 당분 농도\",\"염화나트륨 농도\",\n",
        "                   \"유리 아황산 농도\",\"총 아황산 농도\",\"밀도\",\"pH\",\"황산칼륨 농도\",\"알코올 도수\",\n",
        "                   \"와인의 맛(0~10등급)\", \"class(0:화이트와인, 1:레드와인)\"])\n",
        "\n",
        "df_info.columns = [\"f_info\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYN45mFS7aZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "446975ef-de08-47fa-f00a-590c9b8a5310"
      },
      "source": [
        "df_info"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>주석산 농도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>아세트산 농도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>구연산 농도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>잔류 당분 농도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>염화나트륨 농도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>유리 아황산 농도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>총 아황산 농도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>밀도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>pH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>황산칼륨 농도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>알코올 도수</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>와인의 맛(0~10등급)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>class(0:화이트와인, 1:레드와인)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    f_info\n",
              "0                   주석산 농도\n",
              "1                  아세트산 농도\n",
              "2                   구연산 농도\n",
              "3                 잔류 당분 농도\n",
              "4                 염화나트륨 농도\n",
              "5                유리 아황산 농도\n",
              "6                 총 아황산 농도\n",
              "7                       밀도\n",
              "8                       pH\n",
              "9                  황산칼륨 농도\n",
              "10                  알코올 도수\n",
              "11           와인의 맛(0~10등급)\n",
              "12  class(0:화이트와인, 1:레드와인)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC6gXQBJ7bhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = df.values\n",
        "X = dataset[:,0:12]\n",
        "Y = dataset[:,12]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whx0F9f19N9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델의 설정\n",
        "model = Sequential()\n",
        "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhZoaJ2T9QC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 컴파일\n",
        "model.compile(loss='binary_crossentropy',\n",
        "          optimizer='adam',\n",
        "          metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sVUlR42BMgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7d8ad87-133c-4cc4-b684-e99faf3dd49a"
      },
      "source": [
        "# 모델 실행\n",
        "model.fit(X, Y, epochs=200, batch_size=200)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 975 samples\n",
            "Epoch 1/200\n",
            "975/975 [==============================] - 0s 13us/sample - loss: 1.9141 - acc: 0.2318\n",
            "Epoch 2/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 1.0654 - acc: 0.2308\n",
            "Epoch 3/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.8333 - acc: 0.2349\n",
            "Epoch 4/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.7335 - acc: 0.2164\n",
            "Epoch 5/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.6466 - acc: 0.6256\n",
            "Epoch 6/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.5664 - acc: 0.8626\n",
            "Epoch 7/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.4855 - acc: 0.8800\n",
            "Epoch 8/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.4110 - acc: 0.8944\n",
            "Epoch 9/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.3413 - acc: 0.9097\n",
            "Epoch 10/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.2882 - acc: 0.9108\n",
            "Epoch 11/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.2528 - acc: 0.9169\n",
            "Epoch 12/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.2303 - acc: 0.9179\n",
            "Epoch 13/200\n",
            "975/975 [==============================] - 0s 12us/sample - loss: 0.2166 - acc: 0.9241\n",
            "Epoch 14/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.2093 - acc: 0.9241\n",
            "Epoch 15/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.2042 - acc: 0.9292\n",
            "Epoch 16/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.2016 - acc: 0.9303\n",
            "Epoch 17/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1992 - acc: 0.9333\n",
            "Epoch 18/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1980 - acc: 0.9344\n",
            "Epoch 19/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1969 - acc: 0.9354\n",
            "Epoch 20/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1951 - acc: 0.9364\n",
            "Epoch 21/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1948 - acc: 0.9364\n",
            "Epoch 22/200\n",
            "975/975 [==============================] - 0s 11us/sample - loss: 0.1936 - acc: 0.9364\n",
            "Epoch 23/200\n",
            "975/975 [==============================] - 0s 10us/sample - loss: 0.1928 - acc: 0.9364\n",
            "Epoch 24/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1926 - acc: 0.9354\n",
            "Epoch 25/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1912 - acc: 0.9354\n",
            "Epoch 26/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1912 - acc: 0.9364\n",
            "Epoch 27/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1903 - acc: 0.9364\n",
            "Epoch 28/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1893 - acc: 0.9364\n",
            "Epoch 29/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1887 - acc: 0.9354\n",
            "Epoch 30/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1881 - acc: 0.9364\n",
            "Epoch 31/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1875 - acc: 0.9374\n",
            "Epoch 32/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.1869 - acc: 0.9374\n",
            "Epoch 33/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1864 - acc: 0.9374\n",
            "Epoch 34/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1861 - acc: 0.9374\n",
            "Epoch 35/200\n",
            "975/975 [==============================] - 0s 14us/sample - loss: 0.1854 - acc: 0.9374\n",
            "Epoch 36/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1848 - acc: 0.9374\n",
            "Epoch 37/200\n",
            "975/975 [==============================] - 0s 12us/sample - loss: 0.1847 - acc: 0.9374\n",
            "Epoch 38/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1844 - acc: 0.9374\n",
            "Epoch 39/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1836 - acc: 0.9374\n",
            "Epoch 40/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1834 - acc: 0.9374\n",
            "Epoch 41/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1830 - acc: 0.9374\n",
            "Epoch 42/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1826 - acc: 0.9374\n",
            "Epoch 43/200\n",
            "975/975 [==============================] - 0s 10us/sample - loss: 0.1823 - acc: 0.9364\n",
            "Epoch 44/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1823 - acc: 0.9374\n",
            "Epoch 45/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1811 - acc: 0.9385\n",
            "Epoch 46/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1809 - acc: 0.9374\n",
            "Epoch 47/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1814 - acc: 0.9385\n",
            "Epoch 48/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1806 - acc: 0.9385\n",
            "Epoch 49/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1800 - acc: 0.9385\n",
            "Epoch 50/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1792 - acc: 0.9385\n",
            "Epoch 51/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1788 - acc: 0.9395\n",
            "Epoch 52/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1782 - acc: 0.9395\n",
            "Epoch 53/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1779 - acc: 0.9385\n",
            "Epoch 54/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1779 - acc: 0.9374\n",
            "Epoch 55/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1767 - acc: 0.9385\n",
            "Epoch 56/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1769 - acc: 0.9405\n",
            "Epoch 57/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1758 - acc: 0.9395\n",
            "Epoch 58/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1758 - acc: 0.9395\n",
            "Epoch 59/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1751 - acc: 0.9395\n",
            "Epoch 60/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1747 - acc: 0.9395\n",
            "Epoch 61/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1744 - acc: 0.9385\n",
            "Epoch 62/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1743 - acc: 0.9395\n",
            "Epoch 63/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1735 - acc: 0.9395\n",
            "Epoch 64/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1734 - acc: 0.9395\n",
            "Epoch 65/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.1730 - acc: 0.9385\n",
            "Epoch 66/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1729 - acc: 0.9395\n",
            "Epoch 67/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1721 - acc: 0.9385\n",
            "Epoch 68/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1722 - acc: 0.9374\n",
            "Epoch 69/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1720 - acc: 0.9385\n",
            "Epoch 70/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1708 - acc: 0.9395\n",
            "Epoch 71/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1707 - acc: 0.9385\n",
            "Epoch 72/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1706 - acc: 0.9385\n",
            "Epoch 73/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1696 - acc: 0.9385\n",
            "Epoch 74/200\n",
            "975/975 [==============================] - 0s 11us/sample - loss: 0.1689 - acc: 0.9385\n",
            "Epoch 75/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1682 - acc: 0.9385\n",
            "Epoch 76/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1674 - acc: 0.9374\n",
            "Epoch 77/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1663 - acc: 0.9374\n",
            "Epoch 78/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1658 - acc: 0.9385\n",
            "Epoch 79/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1645 - acc: 0.9374\n",
            "Epoch 80/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1657 - acc: 0.9395\n",
            "Epoch 81/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1640 - acc: 0.9374\n",
            "Epoch 82/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1635 - acc: 0.9395\n",
            "Epoch 83/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1619 - acc: 0.9374\n",
            "Epoch 84/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1615 - acc: 0.9385\n",
            "Epoch 85/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1606 - acc: 0.9385\n",
            "Epoch 86/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1602 - acc: 0.9395\n",
            "Epoch 87/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1599 - acc: 0.9395\n",
            "Epoch 88/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1589 - acc: 0.9395\n",
            "Epoch 89/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.1584 - acc: 0.9405\n",
            "Epoch 90/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.1573 - acc: 0.9405\n",
            "Epoch 91/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1564 - acc: 0.9385\n",
            "Epoch 92/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1557 - acc: 0.9405\n",
            "Epoch 93/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1548 - acc: 0.9415\n",
            "Epoch 94/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1543 - acc: 0.9415\n",
            "Epoch 95/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1544 - acc: 0.9405\n",
            "Epoch 96/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1533 - acc: 0.9405\n",
            "Epoch 97/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1524 - acc: 0.9426\n",
            "Epoch 98/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1522 - acc: 0.9395\n",
            "Epoch 99/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.1511 - acc: 0.9436\n",
            "Epoch 100/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1493 - acc: 0.9446\n",
            "Epoch 101/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1483 - acc: 0.9436\n",
            "Epoch 102/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1473 - acc: 0.9446\n",
            "Epoch 103/200\n",
            "975/975 [==============================] - 0s 10us/sample - loss: 0.1458 - acc: 0.9446\n",
            "Epoch 104/200\n",
            "975/975 [==============================] - 0s 11us/sample - loss: 0.1442 - acc: 0.9477\n",
            "Epoch 105/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1442 - acc: 0.9477\n",
            "Epoch 106/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1416 - acc: 0.9467\n",
            "Epoch 107/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1403 - acc: 0.9456\n",
            "Epoch 108/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1411 - acc: 0.9467\n",
            "Epoch 109/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1382 - acc: 0.9467\n",
            "Epoch 110/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1423 - acc: 0.9456\n",
            "Epoch 111/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1334 - acc: 0.9477\n",
            "Epoch 112/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1343 - acc: 0.9456\n",
            "Epoch 113/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1370 - acc: 0.9426\n",
            "Epoch 114/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1383 - acc: 0.9487\n",
            "Epoch 115/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1400 - acc: 0.9395\n",
            "Epoch 116/200\n",
            "975/975 [==============================] - 0s 10us/sample - loss: 0.1346 - acc: 0.9456\n",
            "Epoch 117/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1321 - acc: 0.9467\n",
            "Epoch 118/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1309 - acc: 0.9467\n",
            "Epoch 119/200\n",
            "975/975 [==============================] - 0s 10us/sample - loss: 0.1333 - acc: 0.9446\n",
            "Epoch 120/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1250 - acc: 0.9477\n",
            "Epoch 121/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1255 - acc: 0.9467\n",
            "Epoch 122/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1228 - acc: 0.9487\n",
            "Epoch 123/200\n",
            "975/975 [==============================] - 0s 12us/sample - loss: 0.1229 - acc: 0.9477\n",
            "Epoch 124/200\n",
            "975/975 [==============================] - 0s 10us/sample - loss: 0.1207 - acc: 0.9487\n",
            "Epoch 125/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1194 - acc: 0.9497\n",
            "Epoch 126/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1194 - acc: 0.9467\n",
            "Epoch 127/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1174 - acc: 0.9487\n",
            "Epoch 128/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.1167 - acc: 0.9487\n",
            "Epoch 129/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1162 - acc: 0.9497\n",
            "Epoch 130/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1152 - acc: 0.9446\n",
            "Epoch 131/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1138 - acc: 0.9477\n",
            "Epoch 132/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1122 - acc: 0.9487\n",
            "Epoch 133/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1117 - acc: 0.9508\n",
            "Epoch 134/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1121 - acc: 0.9477\n",
            "Epoch 135/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1099 - acc: 0.9518\n",
            "Epoch 136/200\n",
            "975/975 [==============================] - 0s 12us/sample - loss: 0.1106 - acc: 0.9477\n",
            "Epoch 137/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.1091 - acc: 0.9477\n",
            "Epoch 138/200\n",
            "975/975 [==============================] - 0s 10us/sample - loss: 0.1066 - acc: 0.9518\n",
            "Epoch 139/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.1058 - acc: 0.9497\n",
            "Epoch 140/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1055 - acc: 0.9528\n",
            "Epoch 141/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1041 - acc: 0.9518\n",
            "Epoch 142/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1052 - acc: 0.9487\n",
            "Epoch 143/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1056 - acc: 0.9569\n",
            "Epoch 144/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1022 - acc: 0.9518\n",
            "Epoch 145/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.1016 - acc: 0.9569\n",
            "Epoch 146/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.1015 - acc: 0.9528\n",
            "Epoch 147/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0998 - acc: 0.9549\n",
            "Epoch 148/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0974 - acc: 0.9559\n",
            "Epoch 149/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0972 - acc: 0.9569\n",
            "Epoch 150/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.1014 - acc: 0.9538\n",
            "Epoch 151/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0959 - acc: 0.9569\n",
            "Epoch 152/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0948 - acc: 0.9569\n",
            "Epoch 153/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0935 - acc: 0.9590\n",
            "Epoch 154/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0952 - acc: 0.9621\n",
            "Epoch 155/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.1026 - acc: 0.9549\n",
            "Epoch 156/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0926 - acc: 0.9631\n",
            "Epoch 157/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0903 - acc: 0.9610\n",
            "Epoch 158/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.0924 - acc: 0.9549\n",
            "Epoch 159/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0914 - acc: 0.9641\n",
            "Epoch 160/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0883 - acc: 0.9621\n",
            "Epoch 161/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0878 - acc: 0.9621\n",
            "Epoch 162/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0868 - acc: 0.9621\n",
            "Epoch 163/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0860 - acc: 0.9662\n",
            "Epoch 164/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0855 - acc: 0.9641\n",
            "Epoch 165/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0845 - acc: 0.9682\n",
            "Epoch 166/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0854 - acc: 0.9682\n",
            "Epoch 167/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0862 - acc: 0.9621\n",
            "Epoch 168/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0867 - acc: 0.9682\n",
            "Epoch 169/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0824 - acc: 0.9641\n",
            "Epoch 170/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0817 - acc: 0.9733\n",
            "Epoch 171/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0818 - acc: 0.9682\n",
            "Epoch 172/200\n",
            "975/975 [==============================] - 0s 9us/sample - loss: 0.0803 - acc: 0.9651\n",
            "Epoch 173/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0842 - acc: 0.9703\n",
            "Epoch 174/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0830 - acc: 0.9621\n",
            "Epoch 175/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0815 - acc: 0.9713\n",
            "Epoch 176/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0812 - acc: 0.9641\n",
            "Epoch 177/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0792 - acc: 0.9703\n",
            "Epoch 178/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0830 - acc: 0.9651\n",
            "Epoch 179/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0775 - acc: 0.9733\n",
            "Epoch 180/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0756 - acc: 0.9672\n",
            "Epoch 181/200\n",
            "975/975 [==============================] - 0s 10us/sample - loss: 0.0744 - acc: 0.9754\n",
            "Epoch 182/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0734 - acc: 0.9744\n",
            "Epoch 183/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0776 - acc: 0.9662\n",
            "Epoch 184/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0735 - acc: 0.9744\n",
            "Epoch 185/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0751 - acc: 0.9733\n",
            "Epoch 186/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0719 - acc: 0.9744\n",
            "Epoch 187/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0722 - acc: 0.9744\n",
            "Epoch 188/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0722 - acc: 0.9703\n",
            "Epoch 189/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0700 - acc: 0.9754\n",
            "Epoch 190/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0702 - acc: 0.9764\n",
            "Epoch 191/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0698 - acc: 0.9744\n",
            "Epoch 192/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0720 - acc: 0.9733\n",
            "Epoch 193/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0728 - acc: 0.9651\n",
            "Epoch 194/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0691 - acc: 0.9733\n",
            "Epoch 195/200\n",
            "975/975 [==============================] - 0s 10us/sample - loss: 0.0685 - acc: 0.9713\n",
            "Epoch 196/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0677 - acc: 0.9774\n",
            "Epoch 197/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0697 - acc: 0.9672\n",
            "Epoch 198/200\n",
            "975/975 [==============================] - 0s 6us/sample - loss: 0.0694 - acc: 0.9733\n",
            "Epoch 199/200\n",
            "975/975 [==============================] - 0s 7us/sample - loss: 0.0684 - acc: 0.9692\n",
            "Epoch 200/200\n",
            "975/975 [==============================] - 0s 8us/sample - loss: 0.0691 - acc: 0.9723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa8736a1ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krq-6GyIBM_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "302ab7b0-0fd1-4ec7-cda0-2a05cb4a7dd4"
      },
      "source": [
        "# 결과 출력\n",
        "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y)[1]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "\n",
            " Accuracy: 0.9713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiUb5IaIBgjL",
        "colab_type": "text"
      },
      "source": [
        "<< deep_code/09_Wine_Checkpoint.py >>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZttK6wp9Rjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 저장 폴더 설정\n",
        "MODEL_DIR = '/content/drive/My Drive/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "   os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-__0yBH9Zeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 저장 조건 설정\n",
        "modelpath=\"/content/drive/My Drive/model/wine1_{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E_CyYAxB7pK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5d24388-0e15-4362-e4c3-4323b6479122"
      },
      "source": [
        "# 모델 실행 및 저장\n",
        "history = model.fit(X, Y, validation_split=0.2, epochs=200, batch_size=200, verbose=0, callbacks=[checkpointer])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.05288, saving model to /content/drive/My Drive/model/wine1_01-0.0529.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.05288 to 0.05226, saving model to /content/drive/My Drive/model/wine1_02-0.0523.hdf5\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.05226\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.05226\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.05226\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.05226\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.05226\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.05226\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.05226\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.05226\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.05226 to 0.05190, saving model to /content/drive/My Drive/model/wine1_11-0.0519.hdf5\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.05190\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.05190\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.05190 to 0.05104, saving model to /content/drive/My Drive/model/wine1_14-0.0510.hdf5\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.05104\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.05104\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.05104\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.05104\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.05104\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.05104 to 0.05027, saving model to /content/drive/My Drive/model/wine1_20-0.0503.hdf5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.05027 to 0.04998, saving model to /content/drive/My Drive/model/wine1_21-0.0500.hdf5\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.04998\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.04998 to 0.04992, saving model to /content/drive/My Drive/model/wine1_23-0.0499.hdf5\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.04992\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.04992\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.04992 to 0.04923, saving model to /content/drive/My Drive/model/wine1_26-0.0492.hdf5\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.04923\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.04923\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.04923 to 0.04872, saving model to /content/drive/My Drive/model/wine1_29-0.0487.hdf5\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.04872\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.04872\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.04872\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.04872\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.04872\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.04872\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.04872 to 0.04821, saving model to /content/drive/My Drive/model/wine1_36-0.0482.hdf5\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.04821 to 0.04805, saving model to /content/drive/My Drive/model/wine1_37-0.0480.hdf5\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.04805\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.04805 to 0.04789, saving model to /content/drive/My Drive/model/wine1_39-0.0479.hdf5\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.04789\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.04789\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.04789 to 0.04680, saving model to /content/drive/My Drive/model/wine1_42-0.0468.hdf5\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.04680\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.04680\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.04680 to 0.04586, saving model to /content/drive/My Drive/model/wine1_45-0.0459.hdf5\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.04586\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.04586 to 0.04512, saving model to /content/drive/My Drive/model/wine1_47-0.0451.hdf5\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.04512\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.04512\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.04512\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.04512\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.04512\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.04512\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.04512 to 0.04504, saving model to /content/drive/My Drive/model/wine1_54-0.0450.hdf5\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.04504\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.04504 to 0.04492, saving model to /content/drive/My Drive/model/wine1_56-0.0449.hdf5\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.04492\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.04492\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.04492\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.04492\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.04492 to 0.04467, saving model to /content/drive/My Drive/model/wine1_61-0.0447.hdf5\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.04467\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.04467 to 0.04384, saving model to /content/drive/My Drive/model/wine1_63-0.0438.hdf5\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.04384\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.04384\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.04384\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.04384\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.04384\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.04384 to 0.04350, saving model to /content/drive/My Drive/model/wine1_69-0.0435.hdf5\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.04350\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.04350 to 0.04319, saving model to /content/drive/My Drive/model/wine1_71-0.0432.hdf5\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.04319\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.04319 to 0.04263, saving model to /content/drive/My Drive/model/wine1_73-0.0426.hdf5\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.04263\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.04263\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.04263\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.04263\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.04263\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.04263\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.04263\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.04263\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.04263 to 0.04201, saving model to /content/drive/My Drive/model/wine1_82-0.0420.hdf5\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.04201 to 0.04197, saving model to /content/drive/My Drive/model/wine1_83-0.0420.hdf5\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.04197\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.04197 to 0.04160, saving model to /content/drive/My Drive/model/wine1_85-0.0416.hdf5\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.04160\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.04160\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.04160 to 0.04148, saving model to /content/drive/My Drive/model/wine1_88-0.0415.hdf5\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.04148\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.04148 to 0.04069, saving model to /content/drive/My Drive/model/wine1_90-0.0407.hdf5\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.04069 to 0.04069, saving model to /content/drive/My Drive/model/wine1_98-0.0407.hdf5\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.04069\n",
            "\n",
            "Epoch 00113: val_loss improved from 0.04069 to 0.04030, saving model to /content/drive/My Drive/model/wine1_113-0.0403.hdf5\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.04030\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.04030\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.04030\n",
            "\n",
            "Epoch 00117: val_loss improved from 0.04030 to 0.03923, saving model to /content/drive/My Drive/model/wine1_117-0.0392.hdf5\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.03923\n",
            "\n",
            "Epoch 00119: val_loss improved from 0.03923 to 0.03913, saving model to /content/drive/My Drive/model/wine1_119-0.0391.hdf5\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.03913\n",
            "\n",
            "Epoch 00121: val_loss improved from 0.03913 to 0.03909, saving model to /content/drive/My Drive/model/wine1_121-0.0391.hdf5\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.03909\n",
            "\n",
            "Epoch 00123: val_loss improved from 0.03909 to 0.03792, saving model to /content/drive/My Drive/model/wine1_123-0.0379.hdf5\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.03792\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.03792\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.03792\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.03792\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.03792\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.03792\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.03792\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.03792\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.03792\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.03792\n",
            "\n",
            "Epoch 00134: val_loss improved from 0.03792 to 0.03757, saving model to /content/drive/My Drive/model/wine1_134-0.0376.hdf5\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.03757\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.03757\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.03757\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.03757\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.03757\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.03757\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.03757\n",
            "\n",
            "Epoch 00142: val_loss improved from 0.03757 to 0.03664, saving model to /content/drive/My Drive/model/wine1_142-0.0366.hdf5\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.03664\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.03664\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.03664\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.03664\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.03664\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.03664 to 0.03633, saving model to /content/drive/My Drive/model/wine1_148-0.0363.hdf5\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.03633\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.03633\n",
            "\n",
            "Epoch 00151: val_loss improved from 0.03633 to 0.03596, saving model to /content/drive/My Drive/model/wine1_151-0.0360.hdf5\n",
            "\n",
            "Epoch 00152: val_loss improved from 0.03596 to 0.03587, saving model to /content/drive/My Drive/model/wine1_152-0.0359.hdf5\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.03587\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.03587\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.03587\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.03587\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.03587\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.03587\n",
            "\n",
            "Epoch 00159: val_loss improved from 0.03587 to 0.03530, saving model to /content/drive/My Drive/model/wine1_159-0.0353.hdf5\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.03530\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.03530\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.03530\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.03530\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.03530\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.03530\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.03530\n",
            "\n",
            "Epoch 00167: val_loss improved from 0.03530 to 0.03519, saving model to /content/drive/My Drive/model/wine1_167-0.0352.hdf5\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.03519\n",
            "\n",
            "Epoch 00184: val_loss improved from 0.03519 to 0.03501, saving model to /content/drive/My Drive/model/wine1_184-0.0350.hdf5\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.03501\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.03501\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.03501\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.03501\n",
            "\n",
            "Epoch 00189: val_loss improved from 0.03501 to 0.03467, saving model to /content/drive/My Drive/model/wine1_189-0.0347.hdf5\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.03467\n",
            "\n",
            "Epoch 00191: val_loss improved from 0.03467 to 0.03447, saving model to /content/drive/My Drive/model/wine1_191-0.0345.hdf5\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.03447\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.03447\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.03447\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.03447\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.03447\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.03447\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.03447\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.03447\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.03447\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}